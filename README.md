# Project Title: Data Insights Pipeline

## Overview
This project sets up a robust data processing and reporting pipeline. It uses a Python script (`execute.py`) to process an Excel data file (`data.xlsx`), converts it to a CSV format (`data.csv`), and then generates a JSON output (`result.json`). A GitHub Actions workflow ensures code quality, automates the data processing, and publishes the generated `result.json` via GitHub Pages.

## Project Structure
```
.
├── .github/              # GitHub Actions workflows
│   └── workflows/
│       └── ci.yml        # CI/CD workflow for linting, processing, and deployment
├── execute.py            # Python script for data processing
├── data.xlsx             # Original Excel data file
├── data.csv              # Converted CSV data file (generated from data.xlsx)
├── index.html            # A simple responsive HTML page (optional, for project context)
├── README.md             # This README file
└── LICENSE               # Project license
```

## Setup and Local Development

### Prerequisites
*   Python 3.11+
*   Pandas 2.3+
*   `openpyxl` (for `data.xlsx` to `data.csv` conversion if done manually, or via script)

### Installation
1.  Clone the repository:
    ```bash
    git clone https://github.com/your-username/your-repo-name.git
    cd your-repo-name
    ```
2.  Install dependencies:
    ```bash
    pip install pandas openpyxl ruff
    ```

### Data Conversion
The `data.xlsx` file needs to be converted to `data.csv` for `execute.py` to process. This conversion is handled automatically in the CI pipeline, but can be done locally:
```python
import pandas as pd
# Assuming data.xlsx is in the same directory
df = pd.read_excel('data.xlsx')
df.to_csv('data.csv', index=False)
```

### Running the Data Processing Script
The `execute.py` script processes `data.csv` and outputs `result.json`.

**Note:** The `execute.py` script has been reviewed and fixed to handle potential errors robustly, including ensuring correct file paths, column existence, data type conversions, and gracefully managing missing or malformed data. It now uses `data.csv` as input and generates `result.json` as output.

To run locally:
```bash
python execute.py
```
This will generate a `result.json` file in the project root.

## Continuous Integration and Deployment (CI/CD)

This project leverages GitHub Actions for automated CI/CD, defined in `.github/workflows/ci.yml`.

### Workflow Steps:
1.  **Code Linting (Ruff):** The `ruff` linter is run on `execute.py` to maintain code quality and style standards. Results are displayed in the CI logs.
2.  **Data Preparation:** `data.xlsx` is converted to `data.csv` as an initial step within the CI. This ensures `execute.py` has the correct input format.
3.  **Execute Data Processing:** The `execute.py` script is executed. Its standard output and errors are captured in the CI logs.
4.  **Publish Results:** The `result.json` file generated by `execute.py` is published as a GitHub Pages artifact. This means the processed data will be accessible via a public URL provided by GitHub Pages (e.g., `https://your-username.github.io/your-repo-name/result.json`).

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.